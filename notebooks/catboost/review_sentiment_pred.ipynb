{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgGDMeiP3YHh",
        "outputId": "4c5d1584-c139-4e07-8b68-798d587b978f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBzlkDKq2b5y",
        "outputId": "b7b49d9c-f481-4f0f-8010-47bb9923b526"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.12/dist-packages (1.2.8)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (4.60.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->catboost) (3.2.4)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (8.5.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas numpy scikit-learn catboost transformers torch joblib tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elqI32fIMfsU",
        "outputId": "1f9e2148-f672-4cfe-dff7-807df7eac915"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleaning text data...\n",
            "Original class distribution:\n",
            " sentiment\n",
            "positive    443434\n",
            "negative     81956\n",
            "neutral      42609\n",
            "Name: count, dtype: int64\n",
            "Class weights: {'negative': np.float64(0.9359155774904834), 'neutral': np.float64(1.800180644202165), 'positive': np.float64(0.2639037783073516)}\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from catboost import CatBoostClassifier, Pool\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "import re\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "DATA_PATH = \"/content/drive/MyDrive/Reviews.csv\"\n",
        "RANDOM_STATE = 42\n",
        "TEST_SIZE = 0.05\n",
        "POSITIVE_THRESHOLD = 0.7\n",
        "\n",
        "dtypes = {\n",
        "    'Id': 'int32',\n",
        "    'ProductId': 'category',\n",
        "    'UserId': 'category',\n",
        "    'Score': 'int8',\n",
        "    'Time': 'int32',\n",
        "    'HelpfulnessNumerator': 'int16',\n",
        "    'HelpfulnessDenominator': 'int16'\n",
        "}\n",
        "df = pd.read_csv(\n",
        "    DATA_PATH,\n",
        "    dtype=dtypes,\n",
        "    usecols=['Score', 'Text'],\n",
        "    nrows=568000\n",
        ")\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'<[^>]+>', '', str(text))\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    return text.lower().strip()\n",
        "\n",
        "print(\"Cleaning text data...\")\n",
        "df['Text'] = df['Text'].apply(clean_text)\n",
        "df = df[df['Text'].str.len() > 5]\n",
        "\n",
        "\n",
        "\n",
        "df['sentiment'] = np.where(\n",
        "    df['Score'] <= 2, 'negative',\n",
        "    np.where(df['Score'] == 3, 'neutral', 'positive')\n",
        ")\n",
        "\n",
        "\n",
        "class_counts = df['sentiment'].value_counts()\n",
        "print(\"Original class distribution:\\n\", class_counts)\n",
        "\n",
        "pos_samples = class_counts['positive']\n",
        "target_pos = int((class_counts.sum() - pos_samples) * POSITIVE_THRESHOLD / (1 - POSITIVE_THRESHOLD))\n",
        "if target_pos < pos_samples:\n",
        "    df_pos = df[df['sentiment'] == 'positive'].sample(n=target_pos, random_state=RANDOM_STATE)\n",
        "    df_balanced = pd.concat([\n",
        "        df[df['sentiment'] != 'positive'],\n",
        "        df_pos\n",
        "    ])\n",
        "else:\n",
        "    df_balanced = df\n",
        "\n",
        "\n",
        "class_weights = {\n",
        "    'negative': 1 / (df_balanced['sentiment'] == 'negative').mean(),\n",
        "    'neutral': 1 / (df_balanced['sentiment'] == 'neutral').mean(),\n",
        "    'positive': 1 / (df_balanced['sentiment'] == 'positive').mean()\n",
        "}\n",
        "\n",
        "total = sum(class_weights.values())\n",
        "class_weights = {k: v * 3 / total for k, v in class_weights.items()}\n",
        "print(\"Class weights:\", class_weights)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "KGio-9h9Y1py",
        "outputId": "c30b821a-8ca8-403e-e43c-ba3dbeca5e10"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'X_train' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-441237348.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train_df1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'review_text'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_test_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'review_text'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m train_pool = Pool(\n\u001b[1;32m      5\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train_df1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ],
      "source": [
        "X_train_df1 = pd.DataFrame({'review_text': X_train.reset_index(drop=True)})\n",
        "X_test_df = pd.DataFrame({'review_text': X_test.reset_index(drop=True)})\n",
        "\n",
        "train_pool = Pool(\n",
        "    data=X_train_df1,\n",
        "    label=y_train,\n",
        "    text_features=['review_text']\n",
        ")\n",
        "\n",
        "test_pool = Pool(\n",
        "    data=X_test_df,\n",
        "    label=y_test,\n",
        "    text_features=['review_text']\n",
        ")\n",
        "\n",
        "class_names = sorted(y_train.unique())\n",
        "print(f\"CatBoost class order: {class_names}\")\n",
        "\n",
        "weight_map = {\n",
        "    'negative': class_weights['negative'],\n",
        "    'neutral': class_weights['neutral'],\n",
        "    'positive': class_weights['positive']\n",
        "}\n",
        "class_weights_ordered = [weight_map[c] for c in class_names]\n",
        "\n",
        "print(f\"Ordered class weights: {dict(zip(class_names, class_weights_ordered))}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7QZr033ZZbn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from catboost import Pool\n",
        "import re\n",
        "\n",
        "print(\"Loading data\")\n",
        "\n",
        "DATA_PATH = \"/content/drive/MyDrive/Reviews.csv\"\n",
        "\n",
        "df = pd.read_csv(\n",
        "    DATA_PATH,\n",
        "    usecols=['Score', 'Text'],\n",
        "    nrows=568000\n",
        ")\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'<[^>]+>', '', str(text))\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    return text.lower().strip()\n",
        "\n",
        "print(\"Cleaning text\")\n",
        "df['Text'] = df['Text'].apply(clean_text)\n",
        "df = df[df['Text'].str.len() > 5]\n",
        "\n",
        "print(\"Creating labels\")\n",
        "df['sentiment'] = np.where(\n",
        "    df['Score'] <= 2, 'negative',\n",
        "    np.where(df['Score'] == 3, 'neutral', 'positive')\n",
        ")\n",
        "\n",
        "print(\"\\nClass distribution:\")\n",
        "print(df['sentiment'].value_counts())\n",
        "\n",
        "\n",
        "from collections import Counter\n",
        "counts = Counter(df['sentiment'])\n",
        "target_size = max(counts['negative'], counts['neutral']) * 3\n",
        "\n",
        "df_balanced = pd.concat([\n",
        "    df[df['sentiment'] == 'negative'],\n",
        "    df[df['sentiment'] == 'neutral'],\n",
        "    df[df['sentiment'] == 'positive'].sample(n=target_size, random_state=42)\n",
        "]).reset_index(drop=True)\n",
        "\n",
        "print(f\"\\nAfter balancing: {len(df_balanced)} samples\")\n",
        "print(df_balanced['sentiment'].value_counts())\n",
        "\n",
        "print(\"\\nSplitting into train/test sets...\")\n",
        "\n",
        "X = df_balanced['Text']\n",
        "y = df_balanced['sentiment']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.05,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {len(X_train)}\")\n",
        "print(f\"Test samples: {len(X_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQLb5uCFZjgd"
      },
      "outputs": [],
      "source": [
        "print(\"\\nConverting text data to DataFrame format for CatBoost...\")\n",
        "X_train_df1 = pd.DataFrame({'review_text': X_train.reset_index(drop=True)})\n",
        "X_test_df = pd.DataFrame({'review_text': X_test.reset_index(drop=True)})\n",
        "\n",
        "train_pool = Pool(\n",
        "    data=X_train_df1,\n",
        "    label=y_train,\n",
        "    text_features=['review_text']\n",
        ")\n",
        "\n",
        "test_pool = Pool(\n",
        "    data=X_test_df,\n",
        "    label=y_test,\n",
        "    text_features=['review_text']\n",
        ")\n",
        "\n",
        "class_names = sorted(y_train.unique())\n",
        "print(f\"CatBoost class order: {class_names}\")\n",
        "\n",
        "weight_map = {\n",
        "    'negative': class_weights['negative'],\n",
        "    'neutral': class_weights['neutral'],\n",
        "    'positive': class_weights['positive']\n",
        "}\n",
        "class_weights_ordered = [weight_map[c] for c in class_names]\n",
        "\n",
        "print(f\"Ordered class weights: {dict(zip(class_names, class_weights_ordered))}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7E1sI0leZ5r_"
      },
      "outputs": [],
      "source": [
        "text_processing = (\n",
        "    \"TextProcessing:type=BM25;\"\n",
        "    \"tokenizers=[{\"\n",
        "        \"tokenizer_id='tok1',\"\n",
        "        \"delimiter=' ',\"\n",
        "        \"token_types='Word,Number,Url,Email',\"\n",
        "        \"lowercasing=true\"\n",
        "    \"}],\"\n",
        "    \"dictionaries=[{\"\n",
        "        \"dictionary_id='dict1',\"\n",
        "        \"gram_order=1,\"\n",
        "        \"max_dictionary_size=50000\"\n",
        "    \"},{\"\n",
        "        \"dictionary_id='dict2',\"\n",
        "        \"gram_order=2\"\n",
        "    \"}]\"\n",
        ")\n",
        "\n",
        "import catboost\n",
        "print(f\"CatBoost version: {catboost.__version__}\")\n",
        "if catboost.__version__ < '1.2.0':\n",
        "    !pip install -U catboost\n",
        "\n",
        "\n",
        "task_type = \"GPU\" if 'COLAB_GPU' in globals() else \"CPU\"\n",
        "print(f\"Using task type: {task_type}\")\n",
        "\n",
        "model = CatBoostClassifier(\n",
        "    iterations=1000,\n",
        "    learning_rate=0.1,\n",
        "    depth=6,\n",
        "    loss_function='MultiClass',\n",
        "    eval_metric='TotalF1:average=Macro',\n",
        "    class_weights=class_weights_ordered,\n",
        "    task_type=task_type,\n",
        "    devices='0' if task_type == \"GPU\" else None,\n",
        "    thread_count=-1,\n",
        "    early_stopping_rounds=50,\n",
        "    verbose=100,\n",
        "    random_seed=RANDOM_STATE,\n",
        "    class_names=class_names,\n",
        "    text_processing=text_processing\n",
        ")\n",
        "\n",
        "try:\n",
        "    print(\"\\nStarting model training \")\n",
        "    model.fit(\n",
        "        train_pool,\n",
        "        eval_set=test_pool,\n",
        "        plot=True,\n",
        "        use_best_model=True\n",
        "    )\n",
        "    print(\"\\nTraining completed successfully!\")\n",
        "    print(f\"Final model has {model.tree_count_} trees\")\n",
        "\n",
        "\n",
        "    if not model.is_fitted():\n",
        "        raise RuntimeError(\"Model not fitted\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nTRAINING FAILED: {str(e)}\")\n",
        "    print(\"Common fixes:\")\n",
        "    raise\n",
        "\n",
        "y_pred = model.predict(X_test_df)\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, digits=3))\n",
        "\n",
        "macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
        "print(f\"\\n F1-Score: {macro_f1:.3f}\")\n",
        "\n",
        "model.save_model(\"review_pred.cbm\")\n",
        "print(\"\\nModel saved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mxfObgWgbaD"
      },
      "outputs": [],
      "source": [
        "from catboost import CatBoostClassifier\n",
        "import pandas as pd\n",
        "\n",
        "model = CatBoostClassifier()\n",
        "model.load_model(\"review_pred.cbm\")\n",
        "\n",
        "print(\"Model loaded\")\n",
        "print(f\"Model has {model.tree_count_} trees\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myyFu3UqgjwJ"
      },
      "outputs": [],
      "source": [
        "def predict_sentiment(text):\n",
        "\n",
        "    import re\n",
        "    def clean_text(txt):\n",
        "        txt = re.sub(r'<[^>]+>', '', str(txt))\n",
        "        txt = re.sub(r'http\\S+', '', txt)\n",
        "        txt = re.sub(r'[^a-zA-Z\\s]', '', txt)\n",
        "        return txt.lower().strip()\n",
        "\n",
        "    cleaned = clean_text(text)\n",
        "\n",
        "    sample_df = pd.DataFrame({'review_text': [cleaned]})\n",
        "\n",
        "    pred_class = model.predict(sample_df)[0]\n",
        "\n",
        "    pred_proba = model.predict_proba(sample_df)[0]\n",
        "    classes = model.classes_\n",
        "    proba_dict = dict(zip(classes, pred_proba))\n",
        "\n",
        "    return pred_class, proba_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJ8BPCj9gpJi"
      },
      "outputs": [],
      "source": [
        "\n",
        "text1 = \"This product broke after one day. Complete waste of money. Do not buy!\"\n",
        "pred1, proba1 = predict_sentiment(text1)\n",
        "print(f\"Review: {text1}\")\n",
        "print(f\"Predicted: {pred1}\")\n",
        "print(f\"Probabilities: {proba1}\\n\")\n",
        "\n",
        "text2 = \"It works fine. Not amazing, not terrible. Does what it should.\"\n",
        "pred2, proba2 = predict_sentiment(text2)\n",
        "print(f\"Review: {text2}\")\n",
        "print(f\"Predicted: {pred2}\")\n",
        "print(f\"Probabilities: {proba2}\\n\")\n",
        "\n",
        "text3 = \"Absolutely love this! Best purchase Iâ€™ve made all year. Fast shipping and perfect quality!\"\n",
        "pred3, proba3 = predict_sentiment(text3)\n",
        "print(f\"Review: {text3}\")\n",
        "print(f\"Predicted: {pred3}\")\n",
        "print(f\"Probabilities: {proba3}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRwQOC7Vg1aw"
      },
      "outputs": [],
      "source": [
        "test_reviews = [\n",
        "    \"Worst thing I ever bought\",\n",
        "    \"Okay for the price\",\n",
        "    \"Highly recommend!\",\n",
        "    \"Not worth it\",\n",
        "    \"Just average\",\n",
        "    \"love it! the best broom i've ever used\",\n",
        "    \"nothing good about this product\",\n",
        "    \"good for the price, but would recommend other options for long term usage\",\n",
        "    \"the best product there is on the market\",\n",
        "    \"shit\",\n",
        "    \"the worst, dont buy, its a replica\",\n",
        "    \"meh\",\n",
        "    \"fine if you're a broke ass who cant afford anything else\",\n",
        "    \"i dont even know where to start with the issues, they are everywhere\",\n",
        "    \"fast shipping, good retailer!\",\n",
        "    'good, but with caveats',\n",
        "    'can recommend',\n",
        "    'can\\'t recommend this product',\n",
        "    \"seller was rude in chat, but other than that i'm satisfied with product overall\",\n",
        "    \"okayish, nothing special to be expected for the price\",\n",
        "    \"wonderful! solves the problem well\",\n",
        "    \"fake advertisement\",\n",
        "    \"great\",\n",
        "    \"bad\",\n",
        "    \"overpriced, look elsewhere\",\n",
        "    \"time to market reduced thanks to it!\",\n",
        "    \"buggy software, wait a few months for a fix if you want to evade the headache\",\n",
        "    \"user experience is lacking\",\n",
        "    \"UX is hit or miss, but ok\"\n",
        "]\n",
        "\n",
        "results = []\n",
        "for text in test_reviews:\n",
        "    pred, proba = predict_sentiment(text)\n",
        "    results.append({\n",
        "        'text': text,\n",
        "        'prediction': pred,\n",
        "        'conf_negative': proba['negative'],\n",
        "        'conf_neutral': proba['neutral'],\n",
        "        'conf_positive': proba['positive']\n",
        "    })\n",
        "\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df[['text', 'prediction']].to_string(index=False))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
